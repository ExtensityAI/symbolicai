[build-system]
requires = ["setuptools", "setuptools-scm"]
build-backend = "setuptools.build_meta"

[tool.uv]
package = true

[project]
name = "symbolicai"
dynamic = ["version"]
authors = [
    {name = "Marius-Constantin Dinu", email = "marius@extensity.ai"},
    {name = "Leoveanu-Condrei Claudiu", email = "leo@extensity.ai"},
]
description = "A Neurosymbolic Perspective on Large Language Models"
readme = "README.md"
requires-python = ">=3.10"
keywords = ["probabilistic programming", "machine learning"]
license = {file = "LICENSE"}
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: BSD License",
    "Operating System :: OS Independent",
]
dependencies = [
    "attrs>=23.2.0",
    "setuptools>=70.0.0",
    "toml>=0.10.2",
    "loguru>=0.7.3",
    "aiohttp>=3.11.13",
    "natsort>=8.3.1",
    "numpy>=1.26.4,<=2.1.3",
    "tqdm>=4.66.3",
    "python-box>=7.1.1",
    "pandas>=2.2.2",
    "scikit-learn>=1.5.0",
    "torch>=2.2.2",
    "torchaudio>=2.2.2",
    "torchvision>=0.17.2",
    "PyYAML>=6.0.1",
    "sympy>=1.12",
    "openai>=1.60.0",
    "anthropic>=0.43.1",
    "google-genai>=1.16.1",
    "pypdf>=4.3.0",
    "ipython>=8.24.0",
    "sentencepiece>=0.2.0",
    "sentence-transformers>=2.5.1",
    "tiktoken>=0.8.0",
    "tika>=2.6.0",
    "colorama>=0.4.6",
    "GitPython>=3.1.42",
    "pathos>=0.3.2",
    "prompt-toolkit>=3.0.43",
    "pydub>=0.25.1",
    "opencv-python>=4.8.1.78",
    "pymongo>=3.12.3, <4.8",
    "requests-toolbelt>=1.0.0",
    "pyvis>=0.3.2",
    "beartype>=0.18.2",
    "pydantic>=2.8.2",
    "pydantic-core>=2.20.1",
    "pydantic-settings>=2.3.4",
    "pycryptodome>=3.20.0",
    "httpx>=0.27.2",
    "nest-asyncio>=1.6.0",
    "rich>=13.9.4"
]

[project.optional-dependencies]
bitsandbytes = ["bitsandbytes>=0.43.1"] # handle separately because of Apple Silicon
blip2        = ["decord>=0.6.0", "salesforce-lavis>=1.0.0", "opencv-python-headless>=4.5.5.64"]
hf           = ["transformers>=4.45.2", "accelerate>=0.33.0", "peft>=0.13.1", "datasets>=3.0.1", "trl>=0.11.3"]
webscraping  = ["beautifulsoup4>=4.12.3", "trafilatura>=2.0.0", "pdfminer.six"]
llama_cpp    = ["llama-cpp-python[server]>=0.3.7"] # handle separately since this dependency may not compile and require special maintenance
wolframalpha = ["wolframalpha>=5.0.0"]
whisper      = ["openai-whisper>=20240930", "numba>=0.60.0"]
serpapi      = ["google_search_results>=2.4.2"]
services     = ["fastapi>=0.110.0", "redis>=5.0.2", "uvicorn>=0.27.1"]
solver       = ["z3-solver>=4.12.6.0"]
all          = [
    "symbolicai[hf]",
    "symbolicai[wolframalpha]",
    "symbolicai[whisper]",
    "symbolicai[webscraping]",
    "symbolicai[serpapi]",
    "symbolicai[services]",
    "symbolicai[solver]"
]

[tool.setuptools.dynamic]
version = {attr = "symai.SYMAI_VERSION"}
[tool.setuptools.package-data]
"*" = ["*.json", "*.md", "*.pytxt"]

[tool.setuptools.packages.find]
include = ["symai*"]
exclude = ["tests", "examples", "notebooks", "outputs", "assets", "app.py"]

[dependency-groups]
dev = [
    "isort>=6.0.1",
    "pytest>=8.3.1",
]

[project.urls]
"Homepage" = "https://extensity.ai"
"GitHub"   = "https://github.com/ExtensityAI/symbolicai"

[project.scripts]
symchat = "symai.chat:run"
symsh   = "symai.shell:run"
sympkg  = "symai.extended.packages.sympkg:run"
symdev  = "symai.extended.packages.symdev:run"
symrun  = "symai.extended.packages.symrun:run"
symconfig = "symai:display_config"
symserver = "symai:run_server"
